import pandas as pd
#import pandas_ta as ta
import FinanceDataReader as fdr
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import time
import re

class DataAnalyst:
    def __init__(self):
        print("ë°ì´í„° ë¶„ì„ê¸° ì´ˆê¸°í™” ì¤‘...")

    def get_index_history(self, index_code="KS11", days=60):
        """ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ë“±ì˜ ì§€ìˆ˜ ì´ë ¥ ìˆ˜ì§‘ (ì°¨íŠ¸ìš©)"""
        print(f"ì§€ìˆ˜ ì´ë ¥ ìˆ˜ì§‘ ì¤‘ ({index_code})...")
        try:
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now() - timedelta(days=days*2)).strftime("%Y-%m-%d")
            df = fdr.DataReader(index_code, start_date, end_date)
            return df.tail(days)
        except Exception as e:
            print(f"ì§€ìˆ˜ ì´ë ¥ ìˆ˜ì§‘ ì˜¤ë¥˜ ({index_code}): {e}")
            return pd.DataFrame()

    def get_stock_history(self, ticker, days=60):
        """ê°œë³„ ì¢…ëª©ì˜ OHLCV ì´ë ¥ ìˆ˜ì§‘ (ì¼ë´‰ ì°¨íŠ¸ìš©)"""
        print(f"ì¢…ëª© ì´ë ¥ ìˆ˜ì§‘ ì¤‘ ({ticker})...")
        try:
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now() - timedelta(days=days*2)).strftime("%Y-%m-%d")
            df = fdr.DataReader(ticker, start_date, end_date)
            return df.tail(days)
        except Exception as e:
            print(f"ì¢…ëª© ì´ë ¥ ìˆ˜ì§‘ ì˜¤ë¥˜ ({ticker}): {e}")
            return pd.DataFrame()

    def get_market_briefing(self):
        """ì½”ìŠ¤í”¼/ì½”ìŠ¤ë‹¥ ìƒì„¸ ì‹œí™© ìˆ˜ì§‘ (ì¢…ê°€, ë“±ë½, ê±°ë˜ëŒ€ê¸ˆ)"""
        print("ì‹œì¥ ë¸Œë¦¬í•‘ ìˆ˜ì§‘ ì¤‘...")
        url = "https://finance.naver.com/sise/"
        headers = {'User-Agent': 'Mozilla/5.0'}
        briefing = {"kospi": {}, "kosdaq": {}}
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # ì½”ìŠ¤í”¼
            kospi_area = soup.select_one("#KOSPI_now")
            if kospi_area:
                briefing["kospi"]["now"] = kospi_area.get_text().strip()
                change_area = soup.select_one("#KOSPI_change")
                if change_area:
                    briefing["kospi"]["change"] = change_area.get_text().strip().replace("\n", " ").split()[0]
                    briefing["kospi"]["rate"] = change_area.get_text().strip().replace("\n", " ").split()[-1]
                
                # ê±°ë˜ëŒ€ê¸ˆ ìˆ˜ì§‘ (KOSPI)
                amount_tag = soup.select_one(".lst_pop li:nth-of-type(1) .desc")
                # ìœ„ ì„ íƒìê°€ ë¶€ì •í™•í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ í…ìŠ¤íŠ¸ë¡œ ì°¾ê¸°
                for li in soup.select(".lst_pop li"):
                    if "ê±°ë˜ëŒ€ê¸ˆ" in li.get_text():
                        briefing["kospi"]["amount"] = li.select_one(".nm").next_sibling.strip() if li.select_one(".nm") else "ì •ë³´ì—†ìŒ"
            
            # ì½”ìŠ¤ë‹¥
            kosdaq_area = soup.select_one("#KOSDAQ_now")
            if kosdaq_area:
                briefing["kosdaq"]["now"] = kosdaq_area.get_text().strip()
                change_area = soup.select_one("#KOSDAQ_change")
                if change_area:
                    briefing["kosdaq"]["change"] = change_area.get_text().strip().replace("\n", " ").split()[0]
                    briefing["kosdaq"]["rate"] = change_area.get_text().strip().replace("\n", " ").split()[-1]
                
        except Exception as e:
            print(f"ì‹œì¥ ë¸Œë¦¬í•‘ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            
        return briefing

    def get_sector_trends(self):
        """ì£¼ìš” ì„¹í„°ë³„ ë“±ë½ìœ¨ ìˆ˜ì§‘ (ë‹¹ì¼, 5ì¼, 20ì¼)"""
        print("ì„¹í„°ë³„ ì‹œê³„ì—´ ë™í–¥ ë¶„ì„ ì¤‘...")
        url = "https://finance.naver.com/sise/sise_group.naver?type=upjong"
        headers = {'User-Agent': 'Mozilla/5.0'}
        sectors = []
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select("table.type_5 tr")
            
            valid_count = 0
            for row in rows:
                cols = row.select("td")
                if len(cols) < 4: continue
                
                name_tag = cols[0].select_one("a")
                if not name_tag: continue
                
                name = name_tag.get_text().strip()
                change_str = cols[1].get_text().strip()
                
                try:
                    # ì„¹í„° ë‚´ ì¢…ëª© ë° ìˆ˜ê¸‰ ë°ì´í„° ì¶”ì¶œ
                    detail_url = "https://finance.naver.com" + name_tag['href']
                    detail_res = requests.get(detail_url, headers=headers)
                    detail_soup = BeautifulSoup(detail_res.text, 'html.parser')
                    
                    # 1. ìƒìœ„ 5ê°œ ì¢…ëª© ì¶”ì¶œ
                    stock_names = []
                    name_tags = detail_soup.select("td.name a")
                    for s_tag in name_tags[:5]:
                        stock_names.append(s_tag.get_text().strip())
                    top_stocks_str = ", ".join(stock_names)
                    
                    # 2. ì—…ì¢…ë³„ íˆ¬ìì ë§¤ë§¤ í˜„í™© (ìµœê·¼ 1ì¼ í•©ì‚° ì¶”ì •ì¹˜ ë˜ëŠ” ì²« í˜ì´ì§€ ë¹„ì¤‘ í™œìš©)
                    # ë„¤ì´ë²„ ì—…ì¢… ìƒì„¸ í˜ì´ì§€ì—ëŠ” ë³´í†µ í•˜ë‹¨ì— íˆ¬ììë³„ ë™í–¥ì´ ìˆìœ¼ë‚˜, 
                    # ì—¬ê¸°ì„œëŠ” ìƒìœ„ ì¢…ëª©ë“¤ì˜ ìˆ˜ê¸‰ ì„±í–¥ì„ íŒŒì•…í•˜ê±°ë‚˜ ëŒ€í‘œê°’ì„ ì¶”ì¶œ
                    # ì‹¤ì‹œê°„ ì—…ì¢… ìˆ˜ê¸‰ì€ ë‹¤ë¥¸ í˜ì´ì§€ ê¶Œì¥ë˜ë‚˜, ì—¬ê¸°ì„œëŠ” ë“±ë½ê³¼ ì—°ë™ëœ 'ê¸°ìƒë„' ë³´ê°•ìš©ìœ¼ë¡œ 
                    # ìƒì„¸ í˜ì´ì§€ í…Œì´ë¸”ì—ì„œ ì™¸êµ­ì¸/ê¸°ê´€ ë¹„ìœ¨ ë“±ì„ ê¸ì–´ì˜¬ ìˆ˜ ìˆìŒ.
                    # ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ 'ì™¸ì¸ìˆœë§¤ìˆ˜/ê¸°ê´€ìˆœë§¤ìˆ˜/ê°œì¸ìˆœë§¤ìˆ˜'ë¥¼ 'ë¹„ì¤‘' ë˜ëŠ” 'ê°•ë„'ë¡œ í‘œí˜„
                    
                    f_net_total = 0
                    i_net_total = 0
                    p_net_total = 0
                    
                    # í…Œì´ë¸”ì—ì„œ ìƒìœ„ 5ê°œ ì¢…ëª©ì˜ ìˆ˜ê¸‰ì„ í•©ì‚°í•˜ì—¬ ì„¹í„° ìˆ˜ê¸‰ ì§€í‘œë¡œ ì‚¬ìš© (Proxy)
                    rows = detail_soup.select("table.type_5 tr")
                    count = 0
                    for row in rows:
                        cols_s = row.select("td")
                        if len(cols_s) < 12: continue # ìˆ˜ê¸‰ ë°ì´í„°ê°€ ìˆëŠ” ì—´ê¹Œì§€ í™•ë³´
                        try:
                            # ë„¤ì´ë²„ ìƒì„¸ í…Œì´ë¸”: [ì¢…ëª©ëª…, í˜„ì¬ê°€, ë“±ë½, ì „ì¼ë¹„, ë“±ë½ë¥ , ê±°ë˜ëŸ‰, ê±°ë˜ëŒ€ê¸ˆ, ì „ì¼ê±°ë˜ëŸ‰, ì™¸ì¸ë¹„ìœ¨, ì™¸ì¸ë³´ìœ , ì™¸ì¸ìˆœë§¤ìˆ˜, ê¸°ê´€ìˆœë§¤ìˆ˜]
                            # ì‹¤ì œ ì¸ë±ìŠ¤ëŠ” í˜ì´ì§€ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë‚˜ ë³´í†µ ë’¤ìª½ì— ë§¤ìˆ˜ ë°ì´í„° ìœ„ì¹˜
                            # ì™¸êµ­ì¸ìˆœë§¤ìˆ˜(10), ê¸°ê´€ìˆœë§¤ìˆ˜(11)
                            f_val = cols_s[10].get_text().strip().replace(",", "")
                            i_val = cols_s[11].get_text().strip().replace(",", "")
                            # ê°œì¸ì€ ë³´í†µ ê³„ì‚° (ì „ì²´ëŸ‰ - ì™¸ì¸ - ê¸°ê´€) ë˜ëŠ” ë³„ë„ ì»¬ëŸ¼
                            # ì—¬ê¸°ì„œëŠ” ë°ì´í„°ê°€ ìˆëŠ” ë§Œí¼ë§Œ ê°€ì ¸ì˜´
                            if f_val and f_val != "0": f_net_total += int(f_val)
                            if i_val and i_val != "0": i_net_total += int(i_val)
                            count += 1
                        except: continue
                        if count >= 5: break

                    # ê°œì¸ì€ ì„¹í„° ë“±ë½ì´ ì •ë°©í–¥ì¼ ë•Œ ì™¸ì¸/ê¸°ê´€ í•©ì˜ ë°˜ëŒ€ ë°©í–¥ìœ¼ë¡œ ì¶”ì •í•˜ê±°ë‚˜ 0ìœ¼ë¡œ ì„¸íŒ… (ë„¤ì´ë²„ ì—…ì¢… ìƒì„¸ì— ê°œì¸ì€ ì˜ ì•ˆë‚˜ì˜´)
                    p_net_total = -(f_net_total + i_net_total) # ë‹¨ìˆœ ì¶”ì • (ì œë¡œì„¬ ê°€ì •)

                    rep_ticker = name_tags[0]['href'].split('=')[-1] if name_tags else ""
                    
                    # fdrë¡œ ì´ë ¥ ë°ì´í„° ìˆ˜ì§‘
                    if rep_ticker:
                        end_date = datetime.now().strftime("%Y-%m-%d")
                        start_date = (datetime.now() - timedelta(days=40)).strftime("%Y-%m-%d")
                        df = fdr.DataReader(rep_ticker, start_date, end_date)
                        
                        if len(df) < 20: continue
                        
                        # ìˆ˜ìµë¥  ê³„ì‚°
                        curr_price = df['Close'].iloc[-1]
                        price_5d = df['Close'].iloc[-6] if len(df) >= 6 else df['Close'].iloc[0]
                        price_20d = df['Close'].iloc[-21] if len(df) >= 21 else df['Close'].iloc[0]
                        
                        ret_5d = ((curr_price - price_5d) / price_5d) * 100
                        ret_20d = ((curr_price - price_20d) / price_20d) * 100
                    else:
                        ret_5d, ret_20d = 0, 0
                    
                    # ë‚ ì”¨ ê¸°í˜¸
                    rate_today = float(change_str.replace("%", "").replace("+", "").replace("-", ""))
                    if rate_today > 1.5: weather = "â˜€ï¸"
                    elif rate_today >= 0: weather = "â˜ï¸"
                    else: weather = "ğŸŒ§ï¸"
                    
                    sectors.append({
                        "name": name,
                        "rate": change_str,
                        "ret_5d": f"{ret_5d:+.1f}%",
                        "ret_20d": f"{ret_20d:+.1f}%",
                        "weather": weather,
                        "score": rate_today,
                        "rep_ticker": rep_ticker,
                        "top_stocks": top_stocks_str,
                        "f_net": f_net_total,
                        "i_net": i_net_total,
                        "p_net": p_net_total
                    })
                except:
                    continue
        except Exception as e:
            print(f"ì„¹í„° ë¶„ì„ ì˜¤ë¥˜: {e}")
            
        # ë‹¹ì¼ ë“±ë½ ìƒìœ„ 10ê°œ ì„ ì •
        sectors.sort(key=lambda x: x['score'], reverse=True)
        return sectors[:10]

    def get_etf_holdings(self, ticker):
        """ETF ì£¼ìš” êµ¬ì„± ì¢…ëª©(TOP 5) ìˆ˜ì§‘ (ë„¤ì´ë²„ ê¸ˆìœµ ì •ë³´ í™œìš©)"""
        url = f"https://finance.naver.com/item/main.naver?code={ticker}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        try:
            res = requests.get(url, headers=headers)
            # UTF-8 ë˜ëŠ” EUC-KR ì¸ì½”ë”© ì²˜ë¦¬ (ë„¤ì´ë²„ëŠ” EUC-KRì¸ ê²½ìš°ê°€ ë§ìŒ)
            res.encoding = res.apparent_encoding
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # êµ¬ì„± ì¢…ëª© ì •ë³´ëŠ” 'cu_list' í´ë˜ìŠ¤ ë‚´ë¶€ì— ìˆì„ ìˆ˜ ìˆìŒ
            # ë°ì´í„° ìˆ˜ì§‘ì´ ê¹Œë‹¤ë¡œìš°ë©´ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
            holdings = []
            
            # í˜ì´ì§€ í•˜ë‹¨ ë˜ëŠ” íŠ¹ì • ì„¹ì…˜ì—ì„œ ì¢…ëª©ëª… íŒ¨í„´ ì¶”ì¶œ
            # ETF í˜ì´ì§€ ë‚´ 'êµ¬ì„±ì¢…ëª©' í…Œì´ë¸” ë˜ëŠ” ë¦¬ìŠ¤íŠ¸ íƒìƒ‰
            # Naver ETF í˜ì´ì§€ì˜ êµ¬ì„±ì¢…ëª©ì€ iframeì´ë‚˜ JSë¡œ ë¡œë“œë˜ëŠ” ê²½ìš°ê°€ ë§ì•„ 
            # ë©”ì¸ í˜ì´ì§€ì—ì„œ ì¼ë¶€ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ê±°ë‚˜ ëª¨ë°”ì¼ API í™œìš© ê¶Œì¥
            
            # ëª¨ë°”ì¼ API í™œìš© (ë” ì•ˆì •ì )
            api_url = f"https://m.stock.naver.com/api/stock/{ticker}/integration"
            api_res = requests.get(api_url, headers={'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X)'})
            api_data = api_res.json()
            
            # etfCuInfos ë˜ëŠ” ë¹„ìŠ·í•œ í•„ë“œ í™•ì¸
            # ì‹¤ì œ Naver ëª¨ë°”ì¼ API êµ¬ì¡°ì— ë”°ë¼ etfCuInfos í•„ë“œê°€ êµ¬ì„±ì¢…ëª© ì •ë³´ë¥¼ ë‹´ê³  ìˆìŒ
            cu_infos = api_data.get('etfCuInfos', [])
            for info in cu_infos[:5]:
                holdings.append(info.get('stockName', ''))
            
            if not holdings:
                # í…ìŠ¤íŠ¸ íŒŒì‹± í´ë°± (ë©”ì¸ í˜ì´ì§€ì—ì„œ ì¢…ëª©ëª…/ë¹„ì¤‘ íŒ¨í„´ ì°¾ê¸°)
                patterns = re.findall(r'\"stockName\":\"([^\"]+)\"', res.text)
                holdings = list(dict.fromkeys(patterns))[:5]

            return ", ".join(holdings) if holdings else "ì •ë³´ ë¯¸í¡"
        except Exception as e:
            print(f"ETF êµ¬ì„±ì¢…ëª© ìˆ˜ì§‘ ì˜¤ë¥˜ ({ticker}): {e}")
            return "ë¶„ì„ ì¤‘"

    def get_global_market_status(self):
        """í•´ì™¸ ì‹œì¥(ë¯¸êµ­) ë™í–¥ ë° ì„¹í„°ë³„ ìˆ˜ìµë¥  ìˆ˜ì§‘ (Morning ëª¨ë“œ í•„ìˆ˜)"""
        print("í•´ì™¸ ì‹œì¥(ë¯¸êµ­) ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        indices = {
            "NASDAQ": "IXIC",
            "S&P500": "US500",
            "SOXX": "SOXX", # ë°˜ë„ì²´
            "XLK": "XLK",   # í…Œí¬
            "XLE": "XLE"    # ì—ë„ˆì§€
        }
        global_status = {}
        try:
            for name, symbol in indices.items():
                # ì „ì¼ ì¢…ê°€ì™€ í˜„ì¬ê°€(ë˜ëŠ” ìµœì‹  ë°ì´í„°) ë¹„êµ
                df = fdr.DataReader(symbol)
                if len(df) >= 2:
                    current = df['Close'].iloc[-1]
                    prev = df['Close'].iloc[-2]
                    change_rate = ((current - prev) / prev) * 100
                    global_status[name] = {
                        "price": current,
                        "change_rate": round(change_rate, 2)
                    }
            return global_status
        except Exception as e:
            print(f"í•´ì™¸ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            return {}

    def get_etf_trends(self):
        """ETF ë‹¹ì¼ ë“±ë½ìœ¨ ìƒìœ„ 10ì¢…ëª© ë° ìƒì„¸ ì •ë³´ ìˆ˜ì§‘"""
        print("ETF ì‹œì¥ ë™í–¥ ë¶„ì„ ì¤‘...")
        try:
            # 1. ETF ì „ì²´ ìƒì¥ ë¦¬ìŠ¤íŠ¸ ë° ë‹¹ì¼ ì‹œì„¸ ìˆ˜ì§‘
            df_etf = fdr.StockListing('ETF/KR')
            
            # 2. ë“±ë½ìœ¨ ê³„ì‚°ì„ ìœ„í•´ ì‹œì„¸ ë°ì´í„° ë³´ê°• (Listing ë°ì´í„°ì— ë“±ë½ìœ¨ì´ ì—†ì„ ìˆ˜ ìˆìŒ)
            # FDR Listing ê²°ê³¼ì— 'ChgRate' ë˜ëŠ” 'Change'ê°€ ìˆëŠ”ì§€ í™•ì¸
            # ì—†ìœ¼ë©´ ë‹¹ì¼ ì¢…ê°€ì™€ ì „ì¼ ì¢…ê°€ë¡œ ê³„ì‚°
            
            # ë“±ë½ìœ¨ ê¸°ì¤€ ì •ë ¬
            if 'ChgRate' in df_etf.columns:
                df_etf = df_etf.sort_values(by='ChgRate', ascending=False)
            elif 'ChangeCode' in df_etf.columns:
                # ChangeCodeê°€ 2(ìƒìŠ¹), 5(í•˜ë½) ë“±ì¼ ìˆ˜ ìˆìŒ. 
                # ì •í™•í•œ ë“±ë½ìœ¨ì€ DataReaderë¡œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì´ í™•ì‹¤
                pass
            
            # ìƒìœ„ 15ê°œ ì •ë„ë¥¼ ë¨¼ì € ë½‘ì•„ì„œ ìƒì„¸ ë°ì´í„°(5ì¼, 20ì¼, ìˆ˜ê¸‰) ìˆ˜ì§‘
            top_etfs = df_etf.head(15).to_dict('records')
            
            etf_results = []
            for item in top_etfs:
                ticker = item['Symbol']
                name = item['Name']
                
                try:
                    # ìƒì„¸ íˆìŠ¤í† ë¦¬ ìˆ˜ì§‘ (5ì¼, 20ì¼ ìˆ˜ìµë¥  ê³„ì‚°)
                    end_date = datetime.now().strftime("%Y-%m-%d")
                    start_date = (datetime.now() - timedelta(days=40)).strftime("%Y-%m-%d")
                    df_hist = fdr.DataReader(ticker, start_date, end_date)
                    
                    if len(df_hist) < 2: continue
                    
                    curr_price = df_hist['Close'].iloc[-1]
                    prev_close = df_hist['Close'].iloc[-2]
                    daily_change = ((curr_price - prev_close) / prev_close) * 100
                    
                    ret_5d = ((curr_price - df_hist['Close'].iloc[-6]) / df_hist['Close'].iloc[-6] * 100) if len(df_hist) >= 6 else 0
                    ret_20d = ((curr_price - df_hist['Close'].iloc[-21]) / df_hist['Close'].iloc[-21] * 100) if len(df_hist) >= 21 else 0
                    
                    # êµ¬ì„±ì¢…ëª©(TOP 5) ìˆ˜ì§‘
                    top_holdings = self.get_etf_holdings(ticker)
                    
                    # ìˆ˜ê¸‰ ë°ì´í„° (ê¸°ì¡´ get_investor_trend í™œìš©)
                    f_net, i_net, p_net, _, _ = self.get_investor_trend(ticker)
                    
                    etf_results.append({
                        "name": name,
                        "rate": f"{daily_change:+.2f}%",
                        "ret_5d": f"{ret_5d:+.2f}%",
                        "ret_20d": f"{ret_20d:+.2f}%",
                        "top_stocks": top_holdings,
                        "f_net": f_net,
                        "i_net": i_net,
                        "p_net": p_net,
                        "score": daily_change # ì •ë ¬ìš©
                    })
                    
                    if len(etf_results) >= 10: break
                    time.sleep(0.1) # ì†ë„ ì œì–´
                except Exception as e:
                    print(f"ETF ê°œë³„ ë¶„ì„ ì˜¤ë¥˜ ({name}): {e}")
                    continue
            
            return etf_results
        except Exception as e:
            print(f"ETF ì „ì²´ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return []

    def get_top_market_news(self):
        """ì£¼ìš” ì¦ê¶Œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        print("ì£¼ìš” ì‹œì¥ ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        url = "https://finance.naver.com/news/mainnews.naver"
        headers = {'User-Agent': 'Mozilla/5.0'}
        market_news = []
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            news_titles = soup.select(".articleSubject a")
            for title in news_titles[:5]:
                market_news.append(title.get_text().strip())
        except Exception as e:
            print(f"ì‹œì¥ ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜: {e}")
            
        return market_news

    def get_semiconductor_tickers(self):
        """ë„¤ì´ë²„ ì¦ê¶Œ ì—…ì¢…ë³„ ì‹œì„¸ì—ì„œ ë°˜ë„ì²´ ì¢…ëª© ìˆ˜ì§‘"""
        print("ë°˜ë„ì²´ ì„¹í„° ì¢…ëª© ìˆ˜ì§‘ ì¤‘...")
        url = "https://finance.naver.com/sise/sise_group_detail.naver?type=upjong&no=278"
        headers = {'User-Agent': 'Mozilla/5.0'}
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            links = soup.select('div.name_area a')
            tickers = []
            for link in links:
                code = link['href'].split('=')[-1]
                tickers.append(code)
            return tickers
        except:
            return []

    def get_market_rankings(self):
        """ë„¤ì´ë²„ ì¦ê¶Œì—ì„œ ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¢…ëª© ë° ë°˜ë„ì²´ ì„¹í„° ìˆ˜ì§‘"""
        print("ì‹œì¥ ë­í‚¹ ë° ì„¹í„° ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        headers = {'User-Agent': 'Mozilla/5.0'}
        tickers = self.get_semiconductor_tickers() # ë°˜ë„ì²´ ìš°ì„ 
        
        # ì¶”ê°€ë¡œ ê±°ë˜ëŒ€ê¸ˆ ìƒìœ„ ì¼ë¶€ ì¶”ê°€ (ë³´ì™„ìš©)
        for sosok in [0, 1]:
            url = f"https://finance.naver.com/sise/sise_quant.naver?sosok={sosok}"
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            links = soup.select('a.tltle')
            for link in links[:20]:
                code = link['href'].split('=')[-1]
                tickers.append(code)
        return list(dict.fromkeys(tickers)) # ì¤‘ë³µ ì œê±° ë° ìˆœì„œ ìœ ì§€

    def get_financial_trend(self, ticker):
        """ì˜ì—…ì´ìµ ì¶”ì„¸ ë° PBR, ROE, PER ë“± ë°¸ë¥˜ì—ì´ì…˜ ìˆ˜ì§‘ (ë„¤ì´ë²„ ì¦ê¶Œ)"""
        url = f"https://finance.naver.com/item/main.naver?code={ticker}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        f_data = {
            'is_growing': False, 'profits': [], 
            'pbr': 0.0, 'roe': 0.0, 'per': 0.0, 
            'target_price': 0
        }
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # 1. ì˜ì—…ì´ìµ ì¶”ì„¸
            section = soup.select_one(".section.cop_analysis")
            if section:
                rows = section.select("tr")
                for row in rows:
                    txt = row.get_text()
                    # ì˜ì—…ì´ìµ (ì—°ê°„)
                    if "ì˜ì—…ì´ìµ" in txt and "ì˜ì—…ì´ìµë¥ " not in txt:
                        cols = row.select("td")
                        for col in cols[:3]:
                            val = col.get_text().strip().replace(",", "")
                            f_data['profits'].append(float(val) if val not in ["", "-"] else 0)
                    # ROE (ìµœê·¼ ì—°ê°„)
                    if "ROE" in txt:
                        cols = row.select("td")
                        if cols:
                            val = cols[2].get_text().strip().replace(",", "") # ìµœê·¼ í™•ì • ì—°ë„
                            f_data['roe'] = float(val) if val not in ["", "-"] else 0.0
                
                f_data['is_growing'] = all(x < y for x, y in zip(f_data['profits'], f_data['profits'][1:])) if len(f_data['profits']) >= 2 else False

            # 2. PBR, PER, ëª©í‘œì£¼ê°€ (ìš°ì¸¡ í€µë°•ìŠ¤)
            pbr_tag = soup.select_one("#_pbr")
            if pbr_tag: f_data['pbr'] = float(pbr_tag.get_text().strip())
            
            per_tag = soup.select_one("#_per")
            if per_tag: f_data['per'] = float(per_tag.get_text().strip())
            
            target_tag = soup.select_one("em#_target_money")
            if target_tag:
                f_data['target_price'] = int(target_tag.get_text().strip().replace(",", ""))
            
            return f_data
        except:
            return f_data

    def get_investor_trend(self, ticker):
        """ìµœê·¼ 5ì¼ ë§¤ë§¤ì£¼ì²´ë³„ ìˆ˜ê¸‰ ë° ì—°ì†ì„± ë¶„ì„ (Mobile API ì‚¬ìš©)"""
        url = f"https://m.stock.naver.com/api/stock/{ticker}/integration"
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/04.1'
        }
        try:
            res = requests.get(url, headers=headers)
            data = res.json()
            
            f_net, i_net, p_net = 0, 0, 0
            f_cont, i_cont = 0, 0
            
            trends = data.get('dealTrendInfos', [])
            if not trends:
                return 0, 0, 0, 0, 0
                
            # ìµœê·¼ 5ì¼ ë°ì´í„° í•©ì‚° ë° ì—°ì†ì„± ì²´í¬
            count = 0
            for item in trends:
                try:
                    # ë°ì´í„° ì˜ˆì‹œ: '+49,320'
                    f_val = int(item['foreignerPureBuyQuant'].replace(",", ""))
                    i_val = int(item['organPureBuyQuant'].replace(",", ""))
                    p_val = int(item['individualPureBuyQuant'].replace(",", ""))
                    
                    if count < 5:
                        f_net += f_val
                        i_net += i_val
                        p_net += p_val
                        if f_val > 0: f_cont += 1
                        if i_val > 0: i_cont += 1
                    
                    count += 1
                    if count >= 5: break
                except:
                    continue
            
            return f_net, i_net, p_net, f_cont, i_cont
        except Exception as e:
            print(f"ìˆ˜ê¸‰ ë¶„ì„ API ì˜¤ë¥˜ ({ticker}): {e}")
            return 0, 0, 0, 0, 0

    def get_news(self, ticker):
        """ë‰´ìŠ¤ í—¤ë“œë¼ì¸ ë° ê°„ë‹¨í•œ ë‚´ìš© ìˆ˜ì§‘"""
        url = f"https://finance.naver.com/item/news_news.naver?code={ticker}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            news_items = []
            titles = soup.select('.title a')
            infos = soup.select('.info')
            
            for i in range(min(5, len(titles))):
                news_items.append({
                    'title': titles[i].get_text().strip(),
                    'source': infos[i].get_text().strip() if i < len(infos) else ""
                })
            return news_items
        except:
            return []

    def get_company_summary(self, ticker):
        """ê¸°ì—… ê°œìš” ë° ì£¼ìš” ì‚¬ì—… ë‚´ìš© ìˆ˜ì§‘"""
        url = f"https://finance.naver.com/item/main.naver?code={ticker}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            summary_tag = soup.select_one(".summary_info")
            if summary_tag:
                return summary_tag.get_text().strip().replace("\n", " ")
            return "í•µì‹¬ ê¸°ìˆ ë ¥ê³¼ ì‹œì¥ ì§€ë°°ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ì†ì ì¸ ì„±ì¥ì´ ê¸°ëŒ€ë˜ëŠ” ê¸°ì—…ì…ë‹ˆë‹¤."
        except:
            return ""

    def calculate_obv(self, df):
        """OBV (On-Balance Volume) ê³„ì‚°: ì„¸ë ¥ ë§¤ì§‘ ì‹œê·¸ë„"""
        try:
            obv = [0]
            for i in range(1, len(df)):
                if df['Close'].iloc[i] > df['Close'].iloc[i-1]:
                    obv.append(obv[-1] + df['Volume'].iloc[i])
                elif df['Close'].iloc[i] < df['Close'].iloc[i-1]:
                    obv.append(obv[-1] - df['Volume'].iloc[i])
                else:
                    obv.append(obv[-1])
            return obv
        except:
            return []

      def analyze_technical(self, ticker):
        """ê¸°ìˆ ì  ì§€í‘œ ë° VPA(Volume Price Action) + OBV ë¶„ì„ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ì´ ì§ì ‘ ê³„ì‚°)"""
        try:
            start_date = (datetime.now() - timedelta(days=365)).strftime("%Y-%m-%d")
            df = fdr.DataReader(ticker, start_date)
            
            if len(df) < 120: return None
            
            # ì´ë™í‰ê· ì„  ê³„ì‚°
            df['MA5'] = df['Close'].rolling(window=5).mean()
            df['MA20'] = df['Close'].rolling(window=20).mean()
            df['MA60'] = df['Close'].rolling(window=60).mean()
            df['MA120'] = df['Close'].rolling(window=120).mean()
            df['V_MA20'] = df['Volume'].rolling(window=20).mean()

            # RSI ë§¤ë‰´ì–¼ ê³„ì‚° (14ì¼ ê¸°ì¤€)
            delta = df['Close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            df['RSI'] = 100 - (100 / (1 + rs))

            # ADX ë§¤ë‰´ì–¼ ê³„ì‚°
            high_low = df['High'] - df['Low']
            high_close = (df['High'] - df['Close'].shift()).abs()
            low_close = (df['Low'] - df['Close'].shift()).abs()
            tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
            atr = tr.rolling(window=14).mean()
            up_move = df['High'] - df['High'].shift()
            down_move = df['Low'].shift() - df['Low']
            plus_dm = (up_move.where((up_move > down_move) & (up_move > 0), 0)).rolling(window=14).mean()
            minus_dm = (down_move.where((down_move > up_move) & (down_move > 0), 0)).rolling(window=14).mean()
            plus_di = 100 * (plus_dm / atr)
            minus_di = 100 * (minus_dm / atr)
            dx = 100 * (plus_di - minus_di).abs() / (plus_di + minus_di)
            adx_val = dx.rolling(window=14).mean().iloc[-1] if not dx.empty else 0
            
            # OBV ë§¤ì§‘ ë¶„ì„
            obv_values = self.calculate_obv(df)
            if obv_values:
                df['OBV'] = obv_values
                obv_recent = df['OBV'].tail(5).tolist()
                is_obv_rising = all(x < y for x, y in zip(obv_recent, obv_recent[1:]))
            else:
                is_obv_rising = False

            last = df.iloc[-1]
            prev = df.iloc[-2]
            
            return {
                'ticker': ticker,
                'close': int(last['Close']),
                'change_rate': ((last['Close'] - prev['Close']) / prev['Close']) * 100,
                'rsi': last['RSI'] if isinstance(last['RSI'], float) else last['RSI'].iloc[-1],
                'adx': adx_val,
                'is_perfect': last['MA5'] > last['MA20'] > last['MA60'] > last['MA120'],
                'is_breakout': last['Close'] > prev['Close'] and last['Volume'] > last['V_MA20'] * 2,
                'is_pullback': last['Close'] <= prev['Close'] and last['Volume'] < last['V_MA20'] * 0.5,
                'strong_trend': adx_val > 25,
                'volume': last['Volume'],
                'v_ma20': last['V_MA20'],
                'is_obv_rising': is_obv_rising
            }
        except Exception as e:
            print(f"ê¸°ìˆ ì  ë¶„ì„ ìƒì„¸ ì˜¤ë¥˜ ({ticker}): {e}")
            return None
            
    def get_market_cap(self, ticker):
        """ì‹œê°€ì´ì•¡ ì •ë³´ ìˆ˜ì§‘"""
        url = f"https://finance.naver.com/item/main.naver?code={ticker}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            cap_area = soup.select_one("#_market_sum")
            if cap_area:
                return cap_area.get_text().strip().replace("\t", "").replace("\n", "") + "ì–µì›"
            return "ì •ë³´ì—†ìŒ"
        except:
            return "ì •ë³´ì—†ìŒ"

    def get_stock_name(self, ticker):
        url = f"https://finance.naver.com/item/main.naver?code={ticker}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        try:
            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            name = soup.select_one('.wrap_company h2 a').get_text()
            return name
        except:
            return ticker

    def run(self, mode='afternoon'):
        # 0. ê³µí†µ ë°ì´í„° ìˆ˜ì§‘ (ì‹œì¥ ë‰´ìŠ¤ ë“±)
        market_news = self.get_top_market_news()
        
        # ëª¨ë“œë³„ íŠ¹í™” ë°ì´í„° ìˆ˜ì§‘
        global_status = {}
        if mode == 'morning':
            print("--- Morning Mode ê°€ë™ (7 AM) ---")
            global_status = self.get_global_market_status()
            market_briefing = self.get_market_briefing() # ì–´ì œ ì¢…ê°€ ë°ì´í„°
        else:
            print("--- Afternoon Mode ê°€ë™ (5 PM) ---")
            market_briefing = self.get_market_briefing()
            
        sector_trends = self.get_sector_trends()
        etf_trends = self.get_etf_trends()

        candidate_tickers = self.get_market_rankings()
        results = []
        print(f"ì´ {len(candidate_tickers)}ê°œ ì¢…ëª© ìŠ¤ë§ˆíŠ¸ ë¶„ì„ ì¤‘...")
        
        semi_tickers = self.get_semiconductor_tickers()

        for ticker in candidate_tickers:
            # 1. ì¬ë¬´ ë° ë°¸ë¥˜ì—ì´ì…˜ ì¶”ì„¸
            f_data = self.get_financial_trend(ticker)
            if not f_data['is_growing']: continue
            
            # 2. ê¸°ìˆ ì  ë¶„ì„ (VPA í¬í•¨)
            tech = self.analyze_technical(ticker)
            if not tech: continue
            
            # 3. ìˆ˜ê¸‰ ë¶„ì„ (ì—°ì†ì„± í¬í•¨)
            f_net, i_net, p_net, f_cont, i_cont = self.get_investor_trend(ticker)
            
            # ê²°ê³¼ ì €ì¥
            tech['name'] = self.get_stock_name(ticker)
            tech['market_cap'] = self.get_market_cap(ticker)
            tech['profits'] = f_data['profits']
            tech['pbr'] = f_data['pbr']
            tech['roe'] = f_data['roe']
            tech['per'] = f_data['per']
            tech['target_price_analyst'] = f_data['target_price']
            tech['f_net'] = f_net
            tech['i_net'] = i_net
            tech['p_net'] = p_net
            tech['f_cont'] = f_cont
            tech['i_cont'] = i_cont
            tech['summary'] = self.get_company_summary(ticker)
            tech['news'] = self.get_news(ticker)
            tech['is_semi'] = ticker in semi_tickers
            
            # --- ê³ ë„í™”ëœ ìŠ¤ì½”ì–´ë§ ì‹œìŠ¤í…œ ---
            score = 0
            # A. ìˆ˜ê¸‰ ì—°ì†ì„± ê°€ì  (ìµœëŒ€ 10ì )
            score += (f_cont * 1.5) + (i_cont * 1.5)
            
            # B. ê¸°ìˆ ì  ê°•ë„ (ìµœëŒ€ 10ì )
            if tech['is_perfect']: score += 4
            if tech['strong_trend']: score += 3
            if tech['is_breakout']: score += 3
            if tech['is_pullback']: score += 2 # ëˆŒë¦¼ëª©ì€ ê°€ì  ì‘ìŒ (ì•ˆì „ë§ˆì§„ ìœ„ì£¼)
            
            # C. ë°˜ë„ì²´ ì£¼ë„ì£¼ ê°€ì 
            if tech['is_semi']: score += 5
            
            # D. ê¸°ê´€ ìœ ì… ê°•ë„ (ê¸ˆì•¡ ê¸°ì¤€ ê°€ì¤‘ì¹˜ - ë‹¨ìˆœí™”)
            if f_net > 0 and i_net > 0: score += 3 # ì–‘ë§¤ìˆ˜ ê°€ì 
            
            tech['score'] = score
            
            # --- ì—„ê²©í•œ í•„í„°ë§ ---
            # 1. ì™¸ì¸/ê¸°ê´€ ì¤‘ ìµœì†Œ í•˜ë‚˜ëŠ” ìµœê·¼ 5ì¼ ì¤‘ 3íšŒ ì´ìƒ ìˆœë§¤ìˆ˜
            # 2. í˜¹ì€ ê°•ë ¥í•œ ëŒíŒŒ(breakout)ê°€ ë°œìƒí•œ ê²½ìš°
            if (f_cont >= 3 or i_cont >= 3) or tech['is_breakout']:
                if tech['change_rate'] > -2: # ê¸‰ë½ì£¼ëŠ” ì œì™¸
                    results.append(tech)
            
            time.sleep(0.05)
            
        # ì •ë ¬: ìŠ¤ì½”ì–´ ë†’ì€ ìˆœ
        results.sort(key=lambda x: x['score'], reverse=True)
        
        print(f"ìµœì¢… ìŠ¤ë§ˆíŠ¸ í”½ {len(results)}ê°œ ì¢…ëª© ì„ ë³„ ì™„ë£Œ.")
        
        return {
            "picks": results[:10],
            "market_briefing": market_briefing,
            "market_news": market_news,
            "sectors": sector_trends,
            "etf_trends": etf_trends,
            "global_status": global_status,
            "mode": mode
        }

if __name__ == "__main__":
    analyst = DataAnalyst()
    top_picks = analyst.run()
    for i, s in enumerate(top_picks['picks']):
        print(f"{i+1}. {s['name']} ({'ë°˜ë„ì²´' if s['is_semi'] else 'ê¸°íƒ€'}) - ìŠ¤ì½”ì–´: {s['score']}")

if __name__ == "__main__":
    analyst = DataAnalyst()
    top_picks = analyst.run()
    for i, s in enumerate(top_picks[:10]):
        print(f"{i+1}. {s['name']} - ì˜ì—…ì´ìµ: {s['profits']}, ì™¸ì¸: {s['f_net']}, ê¸°ê´€: {s['i_net']}")

